{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Adjust the path to the 'preprocess' folder relative to your notebook\n",
    "preprocess_path = os.path.abspath(os.path.join('..', '..', 'preprocess'))\n",
    "sys.path.append(preprocess_path)\n",
    "# Import the necessary functions\n",
    "try:\n",
    "    from plot_transfer import plot_transfer\n",
    "    from load_flight_data import load_flight_data\n",
    "    from find_transfers import find_transfers\n",
    "    print(\"Modules imported successfully\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"Error importing modules: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_data_dropped = load_flight_data(drop_last=True)\n",
    "flight_data_not_dropped = load_flight_data(drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JO/miniforge3/envs/epidemiology-pyenv/lib/python3.11/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/Users/JO/miniforge3/envs/epidemiology-pyenv/lib/python3.11/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "transfer_flight_data_dropped = find_transfers(d=flight_data_dropped, max_transit_time=3, remove_outliers=False, outlier_factor=2, outlier_offset=0)\n",
    "transfer_flight_data_not_dropped = find_transfers(d=flight_data_not_dropped, max_transit_time=3, remove_outliers=False, outlier_factor=2, outlier_offset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7201, 22), (7257, 22))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transfer_flight_data with last row included = 7908 transfers\n",
    "transfer_flight_data_dropped.query(\"transit_time_outlier == False\").shape, transfer_flight_data_not_dropped.query(\"transit_time_outlier == False\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from find_transfers import extract_entries_and_exits\n",
    "entries_and_exits = extract_entries_and_exits(flight_data_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_and_exits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test inferred potential transfer flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-outliers (based on transit time x 2 of expected + 5 minute offset)\n",
    "The offset is to account for very short travel times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize DataFrame to store classifications\n",
    "classification_results_non_outliers = pd.DataFrame(columns=['transfer_id', 'correctly_classified'])\n",
    "\n",
    "# Counter to keep track of classified maps\n",
    "map_count = 0\n",
    "\n",
    "# Escape flag\n",
    "escape = False\n",
    "\n",
    "while not escape:\n",
    "    # Select a random transfer ID from non-outliers\n",
    "    transfer_id = rng.choice(transfer_flight_data.query('transit_time_outlier == False').transfer_id)\n",
    "    \n",
    "    # Print the relevant row of transfer_flight_data\n",
    "    print(f\"Number of maps classified: {map_count}\")\n",
    "\n",
    "    display(transfer_flight_data[transfer_flight_data['transfer_id'] == transfer_id][['transfer_id', 'hospital_name_sending', 'hospital_name_receiving', 'time_in_zone_sending', 'expected_transit_time', 'transit_time', 'transit_time_ratio']])\n",
    "    \n",
    "    # Plot the selected transfer using the plot_transfer function\n",
    "    m = plot_transfer(flight_data, transfer_flight_data, transfer_id)\n",
    "    display(m)\n",
    "    \n",
    "    # Prompt for classification\n",
    "    classification = input(f'Classify Transfer ID {transfer_id} (y/n): ').strip().lower()\n",
    "    \n",
    "    # Validate input\n",
    "    while classification not in ['y', 'n', 'exit']:\n",
    "        print(\"Invalid input. Please enter 'y' or 'n'. To exit, type 'exit'.\")\n",
    "        classification = input(f'Classify Transfer ID {transfer_id} (y/n): ').strip().lower()\n",
    "    \n",
    "    # Check if user wants to exit\n",
    "    if classification == 'exit':\n",
    "        escape = True\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    \n",
    "    # Save classification in DataFrame\n",
    "    classification_results_non_outliers = pd.concat([classification_results_non_outliers, pd.DataFrame({'transfer_id': [transfer_id], 'correctly_classified': [classification]}).astype({'transfer_id': 'int', 'correctly_classified': 'str'})], ignore_index=True)\n",
    "    \n",
    "    # Increment map counter\n",
    "    map_count += 1\n",
    "        \n",
    "    # Clear the output to remove the previous plot\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_results_non_outliers['correctly_classified_bool'] = classification_results_non_outliers['correctly_classified'].map({'y': True, 'n': False})\n",
    "print(\"No samples:\", len(classification_results_non_outliers))\n",
    "print(\"Specificity:\", classification_results_non_outliers['correctly_classified_bool'].sum() / len(classification_results_non_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classification results to CSV\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "file_name = f'classification_results_non_outliers_{timestamp}.csv'\n",
    "classification_results_non_outliers.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataFrame to store classifications\n",
    "classification_results_outliers = pd.DataFrame(columns=['transfer_id', 'correctly_classified'])\n",
    "\n",
    "# Counter to keep track of classified maps\n",
    "map_count = 0\n",
    "\n",
    "# Escape flag\n",
    "escape = False\n",
    "\n",
    "while not escape:\n",
    "    # Select a random transfer ID from non-outliers\n",
    "    transfer_id = rng.choice(transfer_flight_data.query('transit_time_outlier == True').transfer_id)\n",
    "    \n",
    "    # Print the relevant row of transfer_flight_data\n",
    "    print(f\"Number of maps classified: {map_count}\")\n",
    "\n",
    "    display(transfer_flight_data[transfer_flight_data['transfer_id'] == transfer_id][['transfer_id', 'hospital_name_sending', 'hospital_name_receiving', 'time_in_zone_sending', 'expected_transit_time', 'transit_time', 'transit_time_ratio']])\n",
    "    \n",
    "    # Plot the selected transfer using the plot_transfer function\n",
    "    m = plot_transfer(flight_data, transfer_flight_data, transfer_id)\n",
    "    display(m)\n",
    "    \n",
    "    # Prompt for classification\n",
    "    classification = input(f'Classify Transfer ID {transfer_id} (y/n): ').strip().lower()\n",
    "    \n",
    "    # Validate input\n",
    "    while classification not in ['y', 'n', 'exit']:\n",
    "        print(\"Invalid input. Please enter 'y' or 'n'. To exit, type 'exit'.\")\n",
    "        classification = input(f'Classify Transfer ID {transfer_id} (y/n): ').strip().lower()\n",
    "    \n",
    "    # Check if user wants to exit\n",
    "    if classification == 'exit':\n",
    "        escape = True\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    \n",
    "    # Save classification in DataFrame\n",
    "    classification_results_outliers = pd.concat([classification_results_non_outliers, pd.DataFrame({'transfer_id': [transfer_id], 'correctly_classified': [classification]}).astype({'transfer_id': 'int', 'correctly_classified': 'str'})], ignore_index=True)\n",
    "    \n",
    "    # Increment map counter\n",
    "    map_count += 1\n",
    "        \n",
    "    # Clear the output to remove the previous plot\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_results_outliers['correctly_classified_bool'] = classification_results_outliers['correctly_classified'].map({'y': True, 'n': False})\n",
    "print(\"Specificity:\", classification_results_outliers['correctly_classified_bool'].sum() / len(classification_results_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classification results to CSV\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "file_name = f'classification_results_outliers_{timestamp}.csv'\n",
    "classification_results_outliers.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "* Of the included flights, almost all are possible transfer flights. Of those exlucuded based on transit time, almost all seem like reasonable exclusions.\n",
    "* Sofar we can estimate that the specificity > 95%\n",
    "* What about sensitivity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating sensitivity\n",
    "Per se impossible since we have no gold standard. However, if we map some random flights we can check if relevant ones are caught. This is manual labor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsk = flight_data.query(\"reg == 'SEJSK'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_flight = rng.choice(jsk['flight_id'])\n",
    "check_flight_reg = rng.choice(jsk['reg'])\n",
    "check_flight_df = jsk.query(f'flight_id == {check_flight}')[['geometry', 'speed', 'altitude', 'UTC_str']]\n",
    "check_flight_day = jsk.query(f'flight_id == {check_flight}')['date'].values[0]\n",
    "check_flight_df.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_that_day = transfer_flight_data[transfer_flight_data['UTC_out_sending'].dt.date == check_flight_day]\n",
    "flights_that_day.query(f\"reg_sending=='{check_flight_reg}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All flights that day\n",
    "flight_data[flight_data.UTC.dt.date == check_flight_day].query(f'reg == \"{check_flight_reg}\"')[['UTC_str', 'geometry', 'flight_id']].explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get some data on the missing flight\n",
    "from datetime import timedelta\n",
    "missing_flight = 671141277\n",
    "missing_flight_date = flight_data.query(f\"flight_id == {missing_flight}\")['UTC'].dt.date.iloc[0]\n",
    "missing_flight_date_prior = missing_flight_date - timedelta(days=1)\n",
    "missing_flight_reg = flight_data.query(f\"flight_id == {missing_flight}\")['reg'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the flight\n",
    "flight_data.query(f\"flight_id == {missing_flight}\")[['zone_name', 'UTC_str', 'radius', 'speed', 'altitude', 'geometry']].explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at inferred flights that day for the aircraft\n",
    "flights_that_day = transfer_flight_data[transfer_flight_data['UTC_out_sending'].dt.date == missing_flight_date]\n",
    "flights_that_day.query(f\"reg_sending=='{missing_flight_reg}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get entries and exits for the aircraft and day\n",
    "\n",
    "entries_and_exits[entries_and_exits['date'].isin((missing_flight_date_prior, missing_flight_date))].query(f\"reg == '{missing_flight_reg}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SE-JSK: 25/25\n",
    "\n",
    "SE-JSN: 24/25\n",
    "\n",
    "SE-JXA: 10/10\n",
    "\n",
    "SE-JXB: 10/10\n",
    "\n",
    "SE-JXC: 9/10\n",
    "\n",
    "SE-JXD: 20/20\n",
    "\n",
    "SE-JSL: 7/3 (some missing Visby->Karolinska)\n",
    "\n",
    "SE-JSJ: 10/10\n",
    "\n",
    "SE-JSG: 10/10\n",
    "\n",
    "SE-JRA: 10/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epidemiology-pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
